[{"content":"Speculative Tomasulo 仿真算法 一：项目简介 该项目基于作者本人选修的计算机体系结构课程的期末实验项目，实现了Speculative Tomasulo 的仿真算法。\nSpeculative Tomasulo算法是一种用于动态调度指令执行的技术，通常应用于超标量处理器中。该算法通过指令发射、操作数就绪、执行、结果写回等步骤实现指令的乱序执行和并行处理。它利用Reservation Station跟踪指令的操作数可用性，并使用重命名表来处理异常和维护执行状态。通过分支预测和乱序执行，Speculative Tomasulo算法能够最大程度地提高处理器的性能和效率。\n本项目按照Speculative Tomasulo算法的基本原理进行设计，并参照课程教学中的合理假设，最后设计了多个测试输入指令序列并验证算法的正确性。\n二：第三节的附加问题 1. Tomasulo 算法相对于 Scoreboard 算法的优点？同时简述Tomasulo 存在的缺点。 Tomasulo算法相较于Scoreboard算法的优点: Tomasulo引入保留站之后每条通路可以缓冲下多条指令，这样的做法平缓了指令发射的速度； 通过寄存器重命名技术有效地解决了写后写数据冒险问题。在Tomasulo算法中，发生写后写冒险时总是把最新的值写进寄存器，旧值不写进寄存器，但是广播； 通过寄存器重命名技术有效地解决了读后写数据冒险问题。Tomasulo算法里不会出现读后写冒险，因为指令一旦发射，指令就会把能读取的数据保存到保留站，源寄存器是否被改写就与该指令无关。 Tomasulo存在的缺点： Tomasulo算法没办法处理中断，精确中断是指在指令和指令之间如果出现了中断/异常，那么处理器要确保中断/异常之前的所有指令都执行完毕，而中断/异常之后的所有指令都没有执行。Tomasulo并不支持指令按序提交，如果指令没办法按序提交，那就很难处理分支指令，如果有分支预测且分支预测失败的话，很难恢复处理器状态。 Tomasulo算法如果在一个周期内同时多条指令就绪或者多条指令写回，受制于总线以及执行单元数量，无法实现完全并行。并且处理多发射指令时，需要增加寄存器读写口，增加控制逻辑。 Tomasulo算法在处理存储指令的冲突时，需要额外加入控制逻辑以及硬件支持。 2. 简要介绍引入重排序改进 Tomasulo 的原理。 在经典的Tomasulo算法中，指令的提交是乱序的，这可能导致不符合程序员期望的执行顺序，分支指令难以处理。为了解决这个问题，引入了ROB，作为指令执行的缓冲区。ROB保持指令的执行顺序，并在指令执行完毕后等待有序提交。\nROB是一个类似FIFO队列的结构，其中包含了每条指令的信息，如编号、Busy位、State位、Destination和Value等字段。指令在发射时被分配ROB编号，等到执行完毕后再提交。ROB的结构允许指令在执行完毕后保持在队列中，而不立即修改逻辑寄存器。 指令在ROB中按照它们在程序中的顺序等待提交。当一条指令成为ROB中最老的指令时，即ROB的头指针指向该指令，就可以有序提交。这确保了指令在逻辑寄存器中的修改按照程序顺序完成。与此同时，ROB也能代替RS的作用实现寄存器重命名，从而保证指令的效率。\nROB的有序提交机制实现了精确中断，确保了在中断发生时能够保持指令的有序提交，而不会导致程序执行错误。ROB的引入允许在指令执行时清除保留站，从而提高了后续指令的发射效率。通过引入ROB，改进的Tomasulo算法克服了原始Tomasulo算法中的一些限制，使得乱序执行更符合程序员的预期，并提高了整体的性能和灵活性。\n3. 请分析重排序缓存的缺点。 重排序缓存需要更多存储空间：在基于ROB的Tomasulo算法中，一个逻辑寄存器的结果被拷贝到多个地方，数据可能存在逻辑寄存器中，也可能存在保留站中，也可能存在ROB中，即一个数据需要三倍于数据长度的存储空间，从而需要更多资源。 重排序缓存需要更多的硬件资源：指令的源数据可以从寄存器堆、CDB总线和ROB中取得。为了支持指令读取数据，需要在 ROB 中配置读口，增加了处理器内部逻辑和数据传递的布线压力。可能导致关键路径的延长，从而影响整体性能。此外，为了处理 ROB 中的数据，需要在读取数据的线路末尾增加选择器，进一步增加了设计的复杂性。 重排序缓存可能引入延迟：尽管 ROB 可以提高指令级并行性，但在某些情况下，指令需要等待 ROB 中的其他指令完成执行才能提交。这可能引入一定的延迟。 重排序缓存在多发射处理器中具有很大难度。为了满足多个指令同时读取 ROB 中的状态，ROB 需要支持多个读端口。在四发射的机器中，如果每个指令都需要两个读端口，ROB 就需要支持八个读端口。这种多端口读的实现增加了硬件结构的复杂性，可能导致更大的芯片面积和更高的功耗，同时也增加了设计和验证的难度。 三：项目结构 1 2 3 4 5 6 7 8 9 10 Speculative Tomasulo ├─ input // 输入样例 │ ├─ input1.txt │ └─ input2.txt ├─ output // 输出结果 │ ├─ output1.txt │ └─ output2.txt └─ src // 源代码 ├─ main.py // 主程序 └─ cpu_component.py // CPU中的功能单元 请在运行前配置好环境依赖，并使得项目结构如上所示，运行方式：\n1 2 cd src python main.py 或者在IDE中运行main.py\n四：新增假设 针对作业要求中未说明的细节，在本次实验中采用以下假设，假设原理符合课件“Chap03-ILP-Part3-Speculation-v2”内容。\n作业要求中假设有三个加载缓冲区插槽和三个存储缓冲区插槽，因为仿真器架构中并无存储缓冲区、课件与书本内容中均将存储缓冲区与ROB结合，因此在本次实验中假设有三个加载缓冲区插槽，存储缓冲区插槽集成在ROB中实现。 假设Load指令经历IF/EX/WB/COMMIT四个阶段，指令发射与提交各需一个时钟周期，EX执行地址计算与加载内存访问(共需两个时钟周期)；Store 指令经历IF/EX/COMMIT三个阶段，在EX阶段执行地址计算并等待需要写入数据，因为Store指令无需广播，因此直接连接COMMIT阶段，所以在无需等待数据以及满足Commit条件时，Store指令共需三个时钟周期。 假设ROB使用循环队列的方式，队列长度为6。 假设RS保留站的数量分别为：Load为2个、Add为3个、Mult为2个；并且实际的可并行的功能单元数量与RS保留站数量相等，即同一功能单元不同保留站中的指令可以同时执行。 在结果输出部分中，为了能够能明显的突出实现结果，进行以下约定：ROB采用循环队列的模式，因此展示最近的六条ROB记录；RS记录中，若vj、qj中数据是直接从寄存器组中获得，则输出类似于Reg[F1]；若是从总线广播或者ROB与寄存器组连接数据线中获得，则输出类似为#1，具体数值可以参照对应ROB中的value属性(本次实验中，总线参照真实模型传输数据，只是在输出时进行了统一简化)；vk、qk中数据输出类似于#x，表示等待对应ROB x 中结果。此外类型为Load的RS保留站只负责输出Load类型缓存区，Store缓冲区内容集成到ROB中进行输出。其余输出内容均按照假设进行。 最终指令最终执行情况表中，输出格式“(Instruction):(Issue cycle),(Exec comp cycle),(Write result cycle),(Commit cycle)；”。例如LD F6 34 R2: 1,3,4,5，代表该指令在时钟 1 进行发射并完成，在时钟 3 结束时执行完毕，在时钟 4 进行Write result并完成，在时钟 5 进行Commit并完成。 能够实现的指令仅包含两个输入样例中出现过的指令，指令格式参考输入样例中格式。 五：仿真器实现思路与具体实现方法 依照仿真器架构进行设计，设计各个CPU中的功能部件，例如：ROB、RS保留站、FP计算部件、总线、寄存器组、内存等等；最后通过一个CPU类将各个功能部件组合在一起，同时由CPU提供控制逻辑，最大程度还原CPU中Speculative Tomasulo算法工作原理。\n源代码文件中完整代码以及更加详细、可读性高的注释，下面展示部分略去部分注释以及一些较简单的代码，旨在突出本次实验仿真器实现思路与的具体实现方法，突出关键代码。\nCPU 类 CPU 类位于 main.py 中，仿真CPU的工作过程，将在cpu_component中实现的各个CPU中功能单元按照所要求的的仿真器架构搭建起来，总控各个功能单元并在类函数中实现模拟运行、按要求保存运行结果。\nCPU类的私有属性为各个功能单元的实例化，时钟周期以及指令队列\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class CPU: def __init__(self, num_registers, memory_size, num_load_buffers, num_rob_entries, instruction_queue): self.bus = Bus() # 创建总线 self.rob_bus = Bus() # 创建rob使用的数据bus self.register_group = RegisterGroup(num_registers, rob_bus=self.rob_bus) # 创建寄存器组 self.memory = Memory(memory_size, bus=self.bus, num_load_buffers=num_load_buffers) # 创建内存 self.fp_add = FPUnit(unit_type=\u0026#34;Add\u0026#34;, num_reservation_stations=3, execution_cycles={ \u0026#34;ADDD\u0026#34;: 2, \u0026#34;SUBD\u0026#34;: 2 }, bus=self.bus) # 创建浮点数执行单元 self.fp_multd = FPUnit(unit_type=\u0026#34;Mult\u0026#34;, num_reservation_stations=2, execution_cycles={ \u0026#34;MULTD\u0026#34;: 10, \u0026#34;DIVD\u0026#34;: 20 }, bus=self.bus) self.reorder_buffer = ReorderBuffer(num_rob_entries, bus=self.bus, rob_bus=self.rob_bus) self.clock_cycles = 0 # 初始化时钟周期计数 self.instruction_queue = instruction_queue # 设置初始指令队列 CPU 类的 run_simulation 方法模拟整个过程开始，管理CPU时钟。该函数负责调用类中的其他函数，进行模拟指令发射、运行、写回过程：\n调用 issue_instruction 方法发射指令； 调用update_component 方法，执行一个时钟周期，模拟真实环境中各个功能单元根据时钟执行操作更新状态； 调用寄存器组和数据总线的 update 方法，模拟真实环境中寄存器组以及数据总线中根据时钟的数据写回过程； 按要求记录本周期中ROB、RS保留站以及寄存器组状态。 按照输出要求将每阶段的输出写入output文件中，并根据所有功能单元都工作结束后结束模拟。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def run_simulation(self): with open(output_file, \u0026#39;w\u0026#39;) as output: # 用于处理前后两个周期输出相同状态 pre_state = \u0026#34;\u0026#34; same_counter = 0 while True: self.clock_cycles += 1 # 模拟时钟周期开始 print(f\u0026#34;Clock Cycle：{self.clock_cycles}\u0026#34;) self.issue_instructions() # 阶段 1：发射指令 self.update_components() # 阶段 2：更新各个组件 self.register_group.update() # 阶段 3：模拟写回 self.bus.update() self.rob_bus.update() new_state = self.record_component_state(self.clock_cycles) # 记录组件状态到文件，包含处理重复输出操作 ... # 检查新状态是否与前一状态不同 if self.are_all_components_idle(): # 检查是否所有组件都处于空闲状态 ...# 如果是，则模拟结束.按要求添加每条指令四个阶段代表周期 CPU 类的 issue_instruction 方法负责按序发射指令：\n先检查是否有未发射指令； 若有则继续检查是否有空闲的ROB可以发射； 根据指令的不同判断是否有空闲的RS可以发射，并且判断指令的操作数是否就绪； 若指令会更新寄存器则调用寄存器组更新函数，进行记录； 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def issue_instructions(self): if self.instruction_queue: # 检查指令队列是否非空 instruction = self.instruction_queue[0] # 检查指令是否可以发射 sd_vj, sd_qj = self.register_group.read(instruction.destination) rob_index = self.reorder_buffer.issue_instruction(instruction, self.clock_cycles, sd_vj, sd_qj) if not rob_index: # 没有空闲ROB时，发射失败 return False # 根据指令类型调用相应的功能单元 if instruction.opcode in {\u0026#34;ADDD\u0026#34;, \u0026#34;SUBD\u0026#34;}: vj, qj = self.register_group.read(instruction.src1) vk, qk = self.register_group.read(instruction.src2) if self.fp_add.issue_instruction(instruction, vj, vk, qj, qk, rob_index): self.instruction_queue.pop(0) else: self.reorder_buffer.clear_rob() elif instruction.opcode in {\u0026#34;MULTD\u0026#34;, \u0026#34;DIVD\u0026#34;}: ... #类似 elif instruction.opcode == \u0026#34;LD\u0026#34;: ... #类似 elif instruction.opcode == \u0026#34;SD\u0026#34;: self.instruction_queue.pop(0) return else: raise ValueError(f\u0026#34;Error Instruction!\u0026#34;) # 更新目标寄存器的值 self.register_group.write(instruction.destination, rob_index) CPU 类中还有三个方法，但不是本次实验重点部分。 update_components 方法负责调用各个功能部件的更新函数，实现按照时钟的更新(只是简单调用)；record_component_state 方法负责将每个周期的ROB、RS保留站、寄存器组状态转化为符合要求格式的字符串返回；are_all_components_idle方法负责调用各个功能部件的finish函数，用于判断是否整个仿真过程结束；(详细代码与注释可以参考源代码模块)\nReorderBuffer 类 ReorderBuffer类中采用循环队列的方式实现了多条rob条目，通过bus总线进行数据传输，通过rob_bus与存储器进行数据传输。\n1 2 3 4 5 6 class ReorderBuffer: def __init__(self, size, bus, rob_bus): self.size = size + 1 # 多一个位置实现循环队列 self.bus = bus self.rob_bus = rob_bus ... ReorderBuffer 类的 issue_instruction 方法实现指令发射到ROB当中。尝试在ROB缓冲区中创建新的ROB条目，将其加入缓冲区，并更新ROB头尾指针。如果ROB缓冲区未满，成功发射的ROB条目将被标记为\u0026quot;Issue\u0026quot;状态，其发射周期将被记录。对于SD指令，目标寄存器将被置为None，而vj和qj将被记录在SD数据字段中。如果ROB缓冲区已满，则发射失败。\n1 2 3 4 5 6 7 8 9 10 11 def issue_instruction(self, instruction, clock_cycle, vj, qj): self.rob_index_counter += 1 # 创建一个新的ROB条目 rob_entry = ReorderBufferEntry(self.rob_index_counter, instruction) next_tail = (self.tail + 1) % self.size # 尝试将ROB条目加入ROB缓冲区 if next_tail != self.head: # 如果缓冲区未满，加入ROB条目 ...# 处理普通条目与SD条目 return rob_entry.rob_index else: # 如果缓冲区已满，发射指令失败 self.rob_index_counter -= 1 return None ReorderBuffer 类的 update 方法负责更新ROB组中条目。首先检查总线上是否有新数据，然后遍历ROB缓冲区中的每个条目，根据其状态和总线上的数据更新条目状态。同时，将满足条件的条目移动到Commit状态。如果总线上有新数据，且ROB中有对应的条目，则使用总线上的数据更新条目的值，并将其状态设为\u0026quot;Write result\u0026quot;，同时尝试将结果写回寄存器。最后，更新ROB的头指针。\n1 2 3 4 5 6 7 8 9 10 11 def update(self, clock_cycle): label, data = self.bus.read() exec_list = self.bus.exec # 检查总线上是否有新数据 index = self.head # 根据不同条件，更新ROB的四个状态 while index != self.tail: entry = self.entries[index] if entry.state == \u0026#34;Issue\u0026#34; and entry.rob_index in exec_list: entry.state = \u0026#34;Exec\u0026#34; ... # 类似 self.head = self.new_head 因为将存储缓冲区集成到ROB当中，所以ReorderBuffer 类还有一个特殊的update_sd方法：该函数根据SD指令的特殊逻辑更新ROB中的条目状态，包括处理等待的操作数和转移到下一个状态。(与update方法并无太大区别，因此不再展示)\nBus 类 总线类，用于在执行单元之间传递数据和标签。属性包含当前总线上的标签、数据以及新写入的标签、数据。\n1 2 3 4 5 6 7 class Bus: def __init__(self): self.label = \u0026#34;\u0026#34; self.value = \u0026#34;\u0026#34; self.new_label = \u0026#34;\u0026#34; self.new_value = \u0026#34;\u0026#34; self.exec = [] Bus类中还有read、write以及update方法，这些方法负责简单的读写操作，update方法检查总线是否有新的数据，如果有，则更新当前总线的标签和数据，否则清空总线上的标签和数据，并清空执行列表。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def read(self): return (self.label, self.value) def write(self, label, data): if not self.new_label: self.new_value = data self.new_label = label return True else: return False def update(self): if self.new_label: self.value = self.new_value self.label = self.new_label self.new_value = \u0026#34;\u0026#34; self.new_label = \u0026#34;\u0026#34; else: self.value = \u0026#34;\u0026#34; self.label = \u0026#34;\u0026#34; self.exec = [] 说明：真实CPU中总线不会传递当前正在执行指令，因为项目输出中ROB中需要及时更改每个条目状态，因此在借助总线额外传递了一些信息(真实中ROB也不会在执行中更改，为了符合输出要求进行了一些合理修改)。\nFPUnit 类 FPUnit类，模拟浮点运算单元的抽象，用于执行浮点数运算。该类包含多个保留站（ReservationStation）以协调浮点数指令的执行。初始化浮点数运算单元时，需要指定执行单元类型 、保留站数量、操作的执行周期，以及总线对象用于与总线通信。(同时也有一个简单的ReservationStation用以模拟RS保留站，包含RS保留站中各种属性)\nFPUnit 类的 issue_instruction 方法负责将指令发射到保留站中。函数主要是判断是否有可用的保留站，如果成功发射，返回 True；否则返回 False。保留站中参数由CPU控制模块传入，该方法只需填入即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def issue_instruction(self, instruction, vj, vk, qj, qk, rob_index): for rs in self.reservation_stations: if not rs.busy(): # 如果 Reservation Station 可用，发射指令，即在Reservation Station中加入对应属性 rs.busy = True rs.op = instruction.opcode rs.vj = vj rs.vk = vk rs.qj = qj rs.qk = qk rs.dest = instruction.destination rs.rob_index = rob_index rs.remain_time = self.execution_cycles.get(instruction.opcode, 1) rs.issue_this_cycle = True return True # 如果没有可用的 Reservation Station，指令发射失败 return False FPUnit 类的 update 方法负责执行一个周期。它遍历每个保留站，如果该保留站的 busy 字段为 True，则通过 counter 判断指令处于哪个阶段并作相应操作；该函数会返回在该周期执行完毕的指令的 PC，通过总线传递给ROB，实现ROB状态的更新操作\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def update(self): label, data = self.bus.read() # 从总线中读取写入的数据 for rs in self.reservation_stations: if rs.busy: if rs.qj or rs.qk: # 操作数未就绪，判断总线中广播数据是否需要 if data and rs.qj == label: rs.vj = f\u0026#34;#{label}\u0026#34; rs.qj = None elif data and rs.qk == label: rs.vk = f\u0026#34;#{label}\u0026#34; rs.qk = None elif rs.remain_time \u0026gt; 0: # 操作数已经就绪，执行 if rs.issue_this_cycle: # 因为发射指令需要一个周期，因此需要跳过新发射的指令 rs.issue_this_cycle = False continue self.bus.exec.append(rs.rob_index) # 将正在执行EX阶段的指令传递给ROB，用以修改ROB状态 # 执行阶段 rs.remain_time -= 1 if rs.remain_time == 0: # 若执行完成，根据要求输出格式记录结果 if isinstance(rs.vj, str): vj_result = rs.vj else: vj_result = f\u0026#34;Reg[F{rs.vj}]\u0026#34; if isinstance(rs.vk, str): vk_result = rs.vk else: vk_result = f\u0026#34;Reg[F{rs.vk}]\u0026#34; if rs.op == \u0026#34;ADDD\u0026#34;: result = f\u0026#34;{vj_result} + {vk_result}\u0026#34; elif rs.op == \u0026#34;SUBD\u0026#34;: result = f\u0026#34;{vj_result} - {vk_result}\u0026#34; elif rs.op == \u0026#34;MULTD\u0026#34;: result = f\u0026#34;{vj_result} * {vk_result}\u0026#34; elif rs.op == \u0026#34;DIVD\u0026#34;: result = f\u0026#34;{vj_result} / {vk_result}\u0026#34; else: raise ValueError(f\u0026#34;Error operation!\u0026#34;) if not self.bus.write(rs.rob_index, result): # 若当前总线有写入阶段，则需要下个周期再次尝试写入 rs.remain_time += 1 else: rs.busy = False rs.issue_this_cycle = False FPUnit 类的 finish 方法简单的检查是否所有的RS保留站均已经释放，即处于busy=False的状态。若全都空闲，则返回完成；否则返回未完成。(详细代码见源代码模块)\nMemory 类 Memory类，模拟计算机中的内存单元，用于进行数据的存储读取操作。另外，该类包含Load缓冲区(Load Buffer)，使用与上文中FPUnit中一样的数据结构RS（ReservationStation）以模拟Load指令加载内存的执行。初始化浮点数运算单元时，需要指定Load Buffer数量、内存大小，以及总线对象用于与总线通信。\n在Memory类中主要实现的方法为issue_instruction以及update，分别用于发射指令与根据总线结果、每个时钟周期正确更新缓冲区状态。实现方式与上文所示FPUnit中实现方式一致，因此不再赘述。同时也在类中实现了finishh、read、write等简单辅助函数，用以更加真实模拟内存读写情况与辅助CPU调用判断是否完成所有指令。\nRegisterGroup 类 RegisterGroup 类是一个用于管理通用寄存器和基址寄存器的实用工具。通过指定寄存器数量和与重排序缓冲区（ROB）通信的总线对象，创建了一组寄存器，并提供了读取和写入数据的方法。在时钟周期中，通过与ROB通信，可以更新寄存器的状态。实现方法较简单，具体参照源代码模块。(同时有一个简单的Register类用以模拟寄存器，包含寄存器各种状态属性)\n辅助函数与main函数 最后还有一些辅助函数，例如parse_instruction、trans、rs_state等等用于：辅助处理指令，进行适当转换，记录RS保留站状态。(因为实现简单，均不再赘述)。\n主函数模块，负责实例化CPU类，读取指令序列并处理，最后运行模拟过程。\n六：优化项目点 实现了一个周期内总线上只有一次合法的写事务，从而避免了同一周期对总线多次写入造成错误结果。 实现了对于ROB中的条目的清除，用于模拟分支条件判断语句错误时，对应的ROB操作。(更加突出Speculative Tomasulo算法特点) 实现了避免存储器冒险的操作，推测可以消除存储器中的 WAW 和 WAR 冒险；通过额外限制条件解决存储器中的 RAW 冒险：若一条存储指令占用的活动ROB项目的“目的地”字段与一条载入指令的A字段取值匹配，则不允许该载入指令开始执行第二步骤。 操作数的来源可以是ROB、寄存器组、总线，本项目中合理考虑了多条数据线并发读写的情况。 以上优化功能均在代码中进行了注释。\n七：实验结果与分析 实现仿真器的关键组件与思路见上一部分，在完成依赖环境配置之后，运行程序。在主函数中，读取标准输入文件转化为指令队列，设置输出文件，随后实例化CPU类(提供必要参数，本次实验参数参照假设进行设置)并调用类中模拟运行的方法即可。模拟运行会在所有指令运行结束之后，自动停止。\n本次实验完整输出结果见 output1.txt 和 output2.txt，这里举例样例 1 中的前几个时钟周期来说明本程序能够正确仿真CPU中 Tomasulo 动态调度算法，对输入指令进行动态调度。输出参照标准规定输出格式并在上文中对输出含义以及正确性进行了解释\n第 1 个时钟周期，发射第一条指令到ROB以及RS保留站中，RS保留站可以中可以直接读取寄存器组中数据，寄存器组中F6变为busy且对应于ROB条目1，程序输出如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 cycle_1; entry1 : Yes, fld F6 34(R2), Issue, F6, None; entry2 :No,,,,; entry3 :No,,,,; entry4 :No,,,,; entry5 :No,,,,; entry6 :No,,,,; Load1 : Yes, LD, Regs[R2], , , , #1; Load2 : NO,,,,,,; Add1 : NO,,,,,,; Add2 : NO,,,,,,; Add3 : NO,,,,,,; Mult1 : NO,,,,,,; Mult2 : NO,,,,,,; Reorder:F0:;F1:;F2:;F3:;F4:;F5:;F6: 1;F7:;F8:;F9:;F10:; Busy:F0:No;F1:No;F2:No;F3:No;F4:No;F5:No;F6:Yes;F7:No;F8:No;F9:No;F10:No; 第 2 个时钟周期，第一条指令开始执行，ROB中状态变为Exec，同时发射第二条指令到ROB以及RS保留站中，寄存器组中也进行相应修改，程序输出如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 cycle_2; entry1 : Yes, fld F6 34(R2), Exec, F6, None; entry2 : Yes, fld F2 45(R3), Issue, F2, None; entry3 :No,,,,; entry4 :No,,,,; entry5 :No,,,,; entry6 :No,,,,; Load1 : Yes, LD, Regs[R2], , , , #1; Load2 : Yes, LD, Regs[R3], , , , #2; Add1 : NO,,,,,,; Add2 : NO,,,,,,; Add3 : NO,,,,,,; Mult1 : NO,,,,,,; Mult2 : NO,,,,,,; Reorder:F0:;F1:;F2: 2;F3:;F4:;F5:;F6: 1;F7:;F8:;F9:;F10:; Busy:F0:No;F1:No;F2:Yes;F3:No;F4:No;F5:No;F6:Yes;F7:No;F8:No;F9:No;F10:No; 第 3 个时钟周期，第一、二条指令处于执行阶段，发射第三条指令到ROB以及RS保留站中(但是该指令所需的操作数 F2 依赖于第二条指令，尚未就绪，因此相应设置vj与qj)，同时更新寄存器组中状态，程序输出如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 cycle_3; entry1 : Yes, fld F6 34(R2), Exec, F6, None; entry2 : Yes, fld F2 45(R3), Exec, F2, None; entry3 : Yes, fmul.d F0,F2,F4, Issue, F0, None; entry4 :No,,,,; entry5 :No,,,,; entry6 :No,,,,; Load1 : Yes, LD, Regs[R2], , , , #1; Load2 : Yes, LD, Regs[R3], , , , #2; Add1 : NO,,,,,,; Add2 : NO,,,,,,; Add3 : NO,,,,,,; Mult1 : Yes, MULTD, , Regs[F4], #2, , #3; Mult2 : NO,,,,,,; Reorder:F0: 3;F1:;F2: 2;F3:;F4:;F5:;F6: 1;F7:;F8:;F9:;F10:; Busy:F0:Yes;F1:No;F2:Yes;F3:No;F4:No;F5:No;F6:Yes;F7:No;F8:No;F9:No;F10:No; 第 4 个时钟周期，第一条指令执行完毕处于Write Result阶段，结果 Mem(34+Regs[R2]])，进行广播；第二条指令处于执行阶段；第三条指令因为操作数未就绪，仍然处于发射阶段；发射第四条指令，接受到广播的操作数F6，将数据填入vj中（但是该指令所需的操作数 F2 依赖于第二条指令，尚未就绪），程序输出如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 cycle_4; entry1 : Yes, fld F6 34(R2), Write result, F6, Mem[34+Regs[R2]]; entry2 : Yes, fld F2 45(R3), Exec, F2, None; entry3 : Yes, fmul.d F0,F2,F4, Issue, F0, None; entry4 : Yes, fsub.d F8,F6,F2, Issue, F8, None; entry5 :No,,,,; entry6 :No,,,,; Load1 : NO,,,,,,; Load2 : Yes, LD, Regs[R3], , , , #2; Add1 : Yes, SUBD, #1, , , #2, #4; Add2 : NO,,,,,,; Add3 : NO,,,,,,; Mult1 : Yes, MULTD, , Regs[F4], #2, , #3; Mult2 : NO,,,,,,; Reorder:F0: 3;F1:;F2: 2;F3:;F4:;F5:;F6: 1;F7:;F8: 4;F9:;F10:; Busy:F0:Yes;F1:No;F2:Yes;F3:No;F4:No;F5:No;F6:Yes;F7:No;F8:Yes;F9:No;F10:No; 第 5 个时钟周期，第一条判断能够Commit，因此修改自身状态并将结果值写入寄存器F6中，寄存器组进行相应修改；第二条指令执行完毕，将结果 Mem[45+Regs[R3]] 通过总线进行广播，同时第三、四条指令在总线中将需要的数据F2进行读取，转为就绪状态，发射第五条指令（但是该指令所需的操作数 F0 依赖于第三条指令，尚未就绪），程序输出如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 cycle_5; entry1 : No, fld F6 34(R2), Commit, F6, Mem[34+Regs[R2]]; entry2 : Yes, fld F2 45(R3), Write result, F2, Mem[45+Regs[R3]]; entry3 : Yes, fmul.d F0,F2,F4, Issue, F0, None; entry4 : Yes, fsub.d F8,F6,F2, Issue, F8, None; entry5 : Yes, fdid.d F10,F0,F6, Issue, F10, None; entry6 :No,,,,; Load1 : NO,,,,,,; Load2 : NO,,,,,,; Add1 : Yes, SUBD, #1, #2, , , #4; Add2 : NO,,,,,,; Add3 : NO,,,,,,; Mult1 : Yes, MULTD, #2, Regs[F4], , , #3; Mult2 : Yes, DIVD, , #1, #3, , #5; Reorder:F0: 3;F1:;F2: 2;F3:;F4:;F5:;F6:;F7:;F8: 4;F9:;F10: 5; Busy:F0:Yes;F1:No;F2:Yes;F3:No;F4:No;F5:No;F6:No;F7:No;F8:Yes;F9:No;F10:Yes; 第 6 个时钟周期，第二条指令判断能够Commit，将数据写入寄存器F2中，相应修改寄存器组状态；第三、四条在上一个周期操作数就绪，因此该周期中进入执行Exec状态；发射第六条指令到ROB以及RS保留站中（但是该指令所需的操作数 F8 依赖于第四条指令，尚未就绪）。第 7 个时钟周期，状态相同，因此合并输出： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 cycle_6-7; entry1 : No, fld F6 34(R2), Commit, F6, Mem[34+Regs[R2]]; entry2 : No, fld F2 45(R3), Commit, F2, Mem[45+Regs[R3]]; entry3 : Yes, fmul.d F0,F2,F4, Exec, F0, None; entry4 : Yes, fsub.d F8,F6,F2, Exec, F8, None; entry5 : Yes, fdid.d F10,F0,F6, Issue, F10, None; entry6 : Yes, fadd.d F6,F8,F2, Issue, F6, None; Load1 : NO,,,,,,; Load2 : NO,,,,,,; Add1 : Yes, SUBD, #1, #2, , , #4; Add2 : Yes, ADDD, , #2, #4, , #6; Add3 : NO,,,,,,; Mult1 : Yes, MULTD, #2, Regs[F4], , , #3; Mult2 : Yes, DIVD, , #1, #3, , #5; Reorder:F0: 3;F1:;F2:;F3:;F4:;F5:;F6: 6;F7:;F8: 4;F9:;F10: 5; Busy:F0:Yes;F1:No;F2:No;F3:No;F4:No;F5:No;F6:Yes;F7:No;F8:Yes;F9:No;F10:Yes; 执行完毕全部六条指令共需 39 个时钟周期，详细输出结果见output1.txt文件，并且程序运行过程中也加入了一些print帮助理解指令运行状况。最终每条指令发射、执行结束、写回的时钟周期如下：\n1 2 3 4 5 6 LD F6 34 R2: 1,3,4,5 LD F2 45 R3: 2,4,5,6 MULTD F0 F2 F4: 3,15,16,17 SUBD F8 F6 F2: 4,7,8,18 DIVD F10 F0 F6: 5,36,37,38 ADDD F6 F8 F2: 6,10,11,39 八：实验总结 Speculative Tomasulo算法的乱序执行和分支预测能够显著提高处理器的性能和效率。通过充分利用可用的执行单元，并在执行过程中处理异常情况，算法能够实现更高的指令级并行性，从而加速指令的执行。\n算法的Reservation Station和重命名表在处理器设计中起着关键作用。Reservation Station跟踪指令的操作数可用性，允许指令按需发射和执行，而重命名表则用于处理异常和维护执行状态，确保指令的正确执行和结果的正确写回。\n基于作者时间、知识与精力有限，本项目只是一个仿真版的Speculative Tomasulo算法实现。后续还有大量的工作可以进行完善，本项目全部代码与报告展示已经开源于：\n[项目链接](0702ccc/Speculative-Tomasulo (github.com))\n如有错漏之处 敬请指正🤝\n","date":"2024-03-05T11:54:21+08:00","image":"https://0702ccc.github.io/p/speculative-tomasulo/1_hu8f4d4075181c05f48ca1f692a88b4fca_770264_120x120_fill_box_smart1_3.png","permalink":"https://0702ccc.github.io/p/speculative-tomasulo/","title":"Speculative Tomasulo"},{"content":"分布式系统大作业——分布式文件系统\r一、项目简介 该项目基于作者本人选修的分布式系统课程的期末实验项目，实现了简化版的HDFS。在满足分布式系统设计的基本要求上，主要优势为系统有重要的可伸缩性，单个主服务器可以控制数百个块服务器： 。\nHadoop Distributed File System（HDFS）是一个用于存储大规模数据的分布式文件系统，设计用于运行在大型集群上。它被设计为容错性高、可靠性强的系统，适用于运行在廉价硬件上。HDFS采用主从架构，其中包括一个主节点（NameNode）负责管理文件系统的命名空间和客户端的访问，并维护文件系统的元数据，以及多个从节点（DataNode）负责存储实际的数据块。文件被分割成多个数据块并分布存储在不同的DataNode上，从而实现了数据的高可靠性和可扩展性。HDFS被广泛应用于大数据处理和分析领域，成为了Apache Hadoop生态系统中的核心组件之一。\n本项目按照HDFS的基本架构进行设计，采用client-server架构，并实现了文件系统的基本的访问、打开、删除、缓存等功能，同时具有一致性、支持多用户特点。 在设计过程中体现在分布式课程中学习到的一些机制或者思想，例如缓存更新机制、访问控制机制、并行扩展等。并适当的进行了一些简化，例如：将HDFS中将文件进行分片存储的实现简化为对文件不进行分片，整体存储。\n二、文件结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 My_HDFS ├─ namenode // 命名节点 │ ├─ datanode // 数据节点 │ ├─ secondarynamenode // 命名节点备份存储 │ ├─ client // 客户端 │ ├─ file_system.proto // Protocol Buffers定义文件 │ ├─ file_system_pb2 // grpc产生文件 │ └─ file_system_pb2_grpc // grpc产生文件 命名节点（Namenode）：负责维护文件系统的命名空间和元数据信息，包括文件的路径、权限、所有者等、负责处理客户端的元数据操作请求，例如创建文件、删除文件、获取文件元数据等，并通过心跳机制与DataNode通信，维护DataNode的可用性信息。\n命名节点备份存储（SecondaryNamenode）：负责与NameNode交互，定时将下载NameNode中的元数据并在本地进行持久化存储，当NameNode需要恢复时，可从SecondaryNamenode下载文件元数据。\n数据节点（Datanode）：负责实际存储文件数据，每个DataNode都维护一部分文件的数据。处理客户端的数据操作请求，例如读取文件数据、写入文件数据。支持数据复制，将文件数据在多个DataNode之间进行复制，以实现分区容错性。\n客户端（Client）：提供用户接口，使用户能够通过命令行与分布式文件系统进行交互。实现了一些常用文件系统操作，如创建目录、进入目录、回退目录、创建文件、写入数据、读取数据、删除文件等。\nProtocol Buffers定义文件：包含用于定义消息结构、字段和其他相关信息的 ProtoBuf 语法。\n三、应用到的分布式系统概念以及原理等如下所示： 分布式系统：分布式文件系统是建立在多个节点上的文件系统，节点之间协同工作以提供高性能、高可用性和可伸缩性。分布式系统致力于通过将计算任务分配到多个计算机上来提高系统性能和容错性。 通信机制：通信是分布式系统中的基础，涉及到节点之间的消息传递。在本次项目实现中使用了gRPC作为通信框架，实现了高效的远程过程调用，同时采用了 Protocol Buffers 进行数据序列化。 线程：系统节点中使用线程的方式运行一些定期函数，例如发送心跳信息、清理过期节点等，使用多线程的方式可以避免陷入引起中断，造成性能下降。 容错性：分布式系统要具备容错性，即使在节点故障的情况下仍能够继续提供服务。实现中通过数据节点中数据的多次复制（副本机制）来保障系统在节点故障时的可用性。此外，通过DataNode定期向NameNode发送心跳消息，以确保各个节点的正常运行状态，有助于及时发现并处理节点故障，提高了系统的容错性。容错性的实现还包含了启动Secondnary NameNode对主NameNode的文件元数据进行备份，实现持久化存储，从而使得主节点能够从错误中正确恢复。 两阶段提交协议：使用两阶段提交协议，将数据节点分为主节点与次节点，保证写入操作的对于所有存储的数据节点通信时一致，从而保证数据存储的一致性。 一致性：文件系统需要保证一致性，即多个节点对于相同数据的访问要保持一致。本次项目中，应用了瞬时一致性，多个数据节点中的修改时同时发生的。 内容分发：文件系统中保证服务器与客户端缓存一致时，采用了客户端基于Pull的更新方式，这样就无需再服务器端保存有缓存的客户端，从而提升服务器的性能。 并发控制：并发控制是确保多个并发操作不会导致数据不一致的机制，引入了文件锁定机制，以确保在某一时刻只有一个客户端能够修改文件 安全性：安全性是分布式系统中至关重要的一个方面，涉及到用户身份验证、访问控制等问题。本次项目中中考虑了管理员、文件的所有者、读写权限等概念，建立了POSIX权限模型以确保系统的安全性。 四、实现细节 实现的分布式文件系统体系结构流程图大致如下所示，箭头指向代表数据流动方向：\n实现功能： 使用grpc在不同节点之间进行通信 具有常用的文件操作，包括：创建删除目录、进入以及后退目录、列出目录下文件、创建文件、打开文件、删除文件、写入数据、读取数据、对文件设置权限。 文件系统的客户端具有缓存功能，文件信息首先在本地存储搜索，若未搜索到再去请求服务器，同时附加实现了缓存更新算法 数据的可⽤性高，数据在不同的物理机器上创建了多个副本，且多个副本之间能够保持瞬时⼀致性。 支持多⽤户即多个客户端，并行读写文件（锁的粒度为文件大小，读写锁能够支持并发读取、独占修改） 访问权限控制，将用户角色区分为管理员与普通用户，管理员可以设置所有文件的读写权限，文件所有者可以设置对应文件的读写权限，参照posix权限模型实现。 因为源代码实现内容较多（包含一些错误输出信息），因此在下面具体展示中节选重要代码进行展示，详细代码以及注释可以文末代码仓库中的源代码部分\n1. grpc实现方式 在文件 file_system.proto 中定义了服务接口、消息类型以及服务方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 service FileSystemService { // File metadata management rpc CreateFile(FileRequest) returns (FileResponse); rpc DeleteFile(FileRequest) returns (FileResponse); rpc RenameFile(RenameRequest) returns (FileResponse); rpc GetFileMetadata(FileRequest) returns (FileMetadataResponse); // More service ... } message FileRequest { string file_path = 1; string owner = 2; string permissions = 3; } // More message ... 使用 grpc.server创建了gRPC服务器，并将服务器实例添加为服务的实现，将服务器绑定到指定的端口，然后通过启动服务器，使其开始监听gRPC请求。 1 2 3 4 5 name_node = NameNode() # 创建一个 NameNode 实例 server = grpc.server(futures.ThreadPoolExecutor(max_workers=10)) file_system_pb2_grpc.add_FileSystemServiceServicer_to_server(name_node, server) server.add_insecure_port(\u0026#39;[::]:50051\u0026#39;) server.start() 在客户端中，创建gRPC客户端通道，用于与服务器进行通信。 通过调用stub对象的方法（如read_data），实现了对远程gRPC服务的调用。这些调用包含了传递的消息参数，通过Protocol Buffers序列化和反序列化。 1 2 3 data_node_channel = grpc.insecure_channel(selected_data_node) data_node_stub = file_system_pb2_grpc.FileSystemServiceStub(data_node_channel) data_node_response = data_node_stub.ReadData(file_system_pb2.DataRequest(file_path=file_path.strip(),offset=int(offset))) 2. 文件操作： 客户端交互页面：\n将终端通过文本提示用户输入，用户能够查看到当前所在目录，并通过help命令查看文件系统所支持的命令格式。将用户输入的命令进行合理划分之后，交给具体的函数实现各个功能。 1 2 3 4 if command == \u0026#34;help\u0026#34;:... elif command.startswith(\u0026#34;create_file\u0026#34;):... elif command.startswith(\u0026#34;get_m\u0026#34;):... else:... 创建目录、进入目录、后退目录、列出目录下文件：\n目录数据均记录在namenode当中，在本次项目中使用树状结构对目录信息进行记录（模拟真实情况中数据存储在namenode节点的内存中），实现树状结构需要定义类以及一些类方法（更多是数据结构的知识在此不详细展开）。\n客户端根据用户的命令构建相应的gRPC请求对象，并通过gRPC连接调用NameNode提供的相应接口，传递目录路径、新目录的名称或其他相关信息。\nNameNode 接收到请求后，根据请求的类型执行相应的目录操作，比如创建目录、列出目录内容、改变当前工作目录等，涉及到在文件系统的元数据中更新目录结构的信息，并且在执行结束之后响应客户端执行结果。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def MakeDirectory(self, request, context): # 创建目录 directory = request.directory new_directory = request.new_directory parent_node = self.traverse_directory(directory) if parent_node is not None: parent_node.add_child(new_directory) return file_system_pb2.FileResponse(success=True, message=\u0026#34;Directory created successfully.\u0026#34;) else: return file_system_pb2.FileResponse(success=False, message=\u0026#34;Parent directory not found.\u0026#34;) def ListFiles(self, request, context): # 列出目录 directory = request.directory directory_node = self.traverse_directory(directory) if directory_node is not None: files = directory_node.list_children() return file_system_pb2.FileListResponse(files=files) else: return file_system_pb2.FileListResponse() elif command == \u0026#34;cd..\u0026#34;: # 回退目录 self.current_directory = \u0026#34;/\u0026#34;.join(self.current_directory.split(\u0026#34;/\u0026#34;)[:-1]) elif command.startswith(\u0026#34;cd\u0026#34;): # 进入目录 _, directory = command.split(maxsplit=1) self.current_directory = f\u0026#34;{self.current_directory}/{directory.strip()}\u0026#34; 创建文件： 客户端通过gRPC连接调用NameNode提供的相应接口，传递文件路径、拥有者、权限信息。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def CreateFile(self, request, context): file_path = request.file_path owner = request.owner permissions = request.permissions if file_path in self.file_metadata: # 如果该文件已经存在 return file_system_pb2.FileResponse(success=False, message=\u0026#34;File already exists.\u0026#34;) # 获取文件所在的目录 directory = os.path.dirname(file_path) parent_node = self.traverse_directory(directory) if parent_node is not None: # 更新目录结构 parent_node.add_child(os.path.basename(file_path)) self.file_metadata[file_path] = file_system_pb2.FileMetadata(file_path=file_path, size=0, owner=owner, permissions=permissions, version=0) return file_system_pb2.FileResponse(success=True, message=f\u0026#34;File \u0026#39;{file_path}\u0026#39; created successfully.\u0026#34;) else: return file_system_pb2.FileResponse(success=False, message=f\u0026#34;Directory \u0026#39;{directory}\u0026#39; not found.\u0026#34;) 删除文件、重命名文件： 操作过程与创建文件类似，只需要修改namenode中用于管理文件的数据结构即可，非本次项目技术重点(故省略)\n打开文件：\n客户端调用函数get_lock获得对于需要打开文件的读者锁，通过gRPC连接调用NameNode提供的相应接口，传递文件路径、用户，NameNode判断是否有权限打开文件并返回结果，详细实现见下文的锁机制。(打开文件之后可以执行写入、读取、关闭三个操作)\n写入数据\n客户端首先将文件的最新版本缓存到本地中，然后在本地缓存中进行写并将缓存的dirty位置位，将文件版本+1，随后在关闭文件时，若文件为dirty则进行flush。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 def write_file_content(self, file_path, data, offset): # 首先更新缓存中的内容，确保是在最新数据中写入 self.read_file_content(file_path, offset) ...# 修改数据 self.file_cache[file_path][\u0026#34;dirty\u0026#34;] = True #设置脏位 def flush_cache(self, file_path): if self.file_cache[file_path][\u0026#34;dirty\u0026#34;]: self.file_cache[file_path][\u0026#34;version\u0026#34;] += 1 # 获取 DataNode 地址 response = self.name_node_stub.WriteFile( file_system_pb2.FileRequest(file_path=file_path.strip(), owner=self.client_id)) if response.success: data_node_addresses = response.data_node_addresses selected_data_node = data_node_addresses[0] # 建立选定主节点 data_node_channel = grpc.insecure_channel(selected_data_node) data_node_stub = file_system_pb2_grpc.FileSystemServiceStub(data_node_channel) # 刷写缓存中的数据到 DataNode data_node_response = data_node_stub.WriteData( file_system_pb2.DataRequest_main( file_path=file_path.strip(), data=self.file_cache[file_path][\u0026#34;content\u0026#34;], offset=0, nodes=data_node_addresses ) ) ...# 一些输出信息省略 客户端通过gRPC连接调用NameNode提供的相应接口，传递文件路径、用户信息。NameNode接受请求，判断用户是否具有写入文件的权限。满足权限，若第一次写入则返回多个随机的DataNode地址(可以使用一些负载均衡算法)；若是后续修改则返回存有文件的DataNode地址。客户端从返回的地址中，选择主DataNode节点进行连接并传输需要写入的文件数据。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def WriteFile(self, request, context): file_path = request.file_path num_replicas = 3 # 假设每个数据块有3个副本 ... # 一些必要目录判断（重复多次了） # 文件已存在，返回DataNode地址 data_nodes = self.ChooseDataNodes(file_path, num_replicas) return file_system_pb2.DataNodeListResponse(success=True, data_node_addresses=data_nodes) def ClientWriteComplete(self, request, context): ...# 处理客户端写入完成的消息 # 更新元数据 new_metadata = file_system_pb2.FileMetadata( file_path=file_path, size=self.file_metadata[file_path].size, data_node_addresses=data_node_addresses, owner=self.file_metadata[file_path].owner, permissions=self.file_metadata[file_path].permissions, version=version, ) self.file_metadata[file_path] = new_metadata return file_system_pb2.FileResponse(success=True, message=\u0026#34;Write complete message processed.\u0026#34;) 主DataNode节点收到客户端请求后，使用两阶段提交协议保证写入的原子性。主DataNode节点向多个次节点发送Vote-request信息，次节点判断之后根据自身情况返回Vote-commit或者Vote-abort信息，主节点统计返回信息并作出最终决定，发送Global-commit或者Global-abort给次节点，所有节点对于数据作出相同响应。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def WriteData(self, request, context): # 获取主节点和次节点列表 main_node = request.nodes[0] secondary_nodes = request.nodes[1:] # 阶段一：向所有次节点发送Prepare请求 prepare_responses = [] for secondary_node in secondary_nodes: vote_request = file_system_pb2.FileRequest(file_path=file_path) with grpc.insecure_channel(secondary_node) as channel: stub = file_system_pb2_grpc.FileSystemServiceStub(channel) prepare_response = stub.Prepare(vote_request) prepare_responses.append(prepare_response) if all(response.success for response in prepare_responses): # 检查所有Prepare响应 # 若所有相应均为Vote-Commit 阶段二：向所有次节点发送Global-Commit for secondary_node in secondary_nodes: with grpc.insecure_channel(secondary_node) as channel: stub = file_system_pb2_grpc.FileSystemServiceStub(channel) commit_response = stub.Commit(request) ...# 更新数据存储 return file_system_pb2.FileResponse(success=True, message=f\u0026#34;write completed\u0026#34;) else: ...# 如果有任何Prepare请求失败，阶段二：向所有次节点发送Global-Abort def Prepare(self, request, context): # 进行简化，都返回可以Commit 实际文件系统需要要进行判断 return file_system_pb2.FileResponse(success=True, message=f\u0026#34;Vote_Commit\u0026#34;) def Commit(self, request, context): # 更新数据存储 current_data = self.data_storage[file_path] updated_data = current_data[:offset] + data + current_data[offset + len(data):] self.data_storage[file_path] = updated_data return file_system_pb2.FileResponse(success=True, message=\u0026#34;Copy successful\u0026#34;) 读取数据\n客户端首先在缓存中寻找是否有对应文件内容，并通过与NameNode通信获取该文件的最新版本号。若缓存中是最新版本，则直接读取缓存，若不存在缓存或缓存过期则运行读取的过程。\n客户端通过gRPC连接调用NameNode提供的相应接口，传递文件路径、用户信息。NameNode接受请求，判断用户是否具有读取文件的权限，若有则返回多个存储有该文件内容的DataNode节点地址。客户端从返回的地址多个地址中，选择最合适的DataNode节点进行连接并读取文件数据（本次实验中使用的是随机选择，具体实践中应考虑网络耗费等）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def read_file_content(self, file_path, offset): # 尝试从缓存中获取文件内容 cached_entry = self.file_cache.get(file_path) file_response = self.name_node_stub.GetFileVersion(file_system_pb2.FileRequest(file_path=file_path.strip())) file_version = file_response.version if cached_entry: cached_content = cached_entry[\u0026#34;content\u0026#34;] cached_version = cached_entry[\u0026#34;version\u0026#34;] if cached_version \u0026gt;= file_version: return cached_content[offset:] if file_version == 0: self.file_cache[file_path] = {\u0026#34;content\u0026#34;: b\u0026#34;\u0026#34;, \u0026#34;version\u0026#34;: file_version, \u0026#34;dirty\u0026#34;: False} return None # 如果缓存中不存在，从 DataNode 获取文件内容 response = self.name_node_stub.GetDatanode( file_system_pb2.FileRequest(file_path=file_path.strip(), owner=self.client_id)) if response.success: data_node_addresses = response.data_node_addresses selected_data_node = random.choice(data_node_addresses) data_node_channel = grpc.insecure_channel(selected_data_node) data_node_stub = file_system_pb2_grpc.FileSystemServiceStub(data_node_channel) data_node_response = data_node_stub.ReadData( file_system_pb2.DataRequest( file_path=file_path.strip(), offset=int(offset), ) ) # 将获取到的文件内容放入缓存 self.file_cache[file_path] = {\u0026#34;content\u0026#34;: data_node_response.data, \u0026#34;version\u0026#34;: file_version, \u0026#34;dirty\u0026#34;: False} return data_node_response.data[offset:] else: return None def GetDatanode(self, request, context): # NameNode返回存有对应文件的数据节点 ... #实现较简单 具体代码可以看源代码模块 def GetFileVersion(self, request, context): # NameNode返回存有对应文件的版本号 ... #实现较简单 具体代码可以看源代码模块 def ReadData(self, request, context)：#DataNode返回文件具体内容 ... #实现较简单 具体代码可以看源代码模块 关闭文件\n与打开文件类似，客户端调用函数unlock释放对应文件的读写锁，如果缓存中的文件为脏数据则进行flush。通过gRPC连接调用NameNode提供的相应接口，传递文件路径、用户，NameNode对文件解锁并返回结果，详细实现见下文的锁机制。 3. 缓存与缓存更新机制： 在本次项目中实现了缓存以及缓存更新，客户端读写一个文件时都先从本地缓存(使用字典来模拟真实客户端的内存)中寻找是否有相应的文件，若没有则再去服务器中读取。与此同时，客户端会向NameNode节点请求对应文件的最新版本号，用pull的策略来保证服务器与本地缓存的一致性。\n采用了write-back(回写的缓存更新策略)，为每个本地缓存中文件维护一个dirty位，若进行了写入操作则置dirty位并在最终关闭文件的时候向服务器写回(flush)。Write-back 缓存写入策略的主要优点包括提高性能、减少主存带宽需求、累积写入以减少写回次数，并且通过版本号以及锁机制保证一致性。\n代码在上文write_data与read_data操作中有过涉及，因此不再赘述。\n4. 多副本之间一致性： 为了保证数据的可用性与文件系统的性能，数据创建了多个副本，且运行多个DataNode程序模拟多个机器。读取数据时，选择一个服务器的副本进行读取；写入数据时，采用瞬时一致性，客户端首先与NameNode通信获取写入DataNode地址，然后与主DataNode通信并传递写入数据。主DataNode与次DataNode之间采用二阶段提交协议保证写入的一致性（具体过程见上文写入数据操作）。两阶段提交协议保证了分布式系统中的事务一致性，即所有节点都要么提交事务，要么中止事务。\n有关文件的元数据信息存储在NameNode当中，并且为了恢复，定时将数据信息传递给Secondary NameNode进行持久化存储，在此过程中保证NameNode中元数据的一致性。\n5. 多用户并行读写(锁机制)： 文件系统支持多用户并发访问，采用读写锁的机制来保证不会冲突，读写锁以元数据的形式存储在NameNode节点中。读写锁能够读操作频繁的情况下允许多个线程同时读取数据，但在写操作进行时禁止读取和其他写操作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def LockFile(self, request, context): ...# 读取 lock = self.file_locks[file_path] lock.lock_time = time.time() # 更新锁的时间 if lock_type == \u0026#34;read\u0026#34;: ...# 权限检查 if lock.writer is None or lock.writer == user: lock.readers.add(user) return file_system_pb2.FileResponse(success=True,message=f\u0026#34;File opened successfully with {lock_type} lock.\u0026#34;) else: return file_system_pb2.FileResponse(success=False, message=\u0026#34;File is writen by another user,can not read.\u0026#34;) elif lock_type == \u0026#34;write\u0026#34;: ...# 权限检查 if (lock.readers == {user} or not lock.readers) and (lock.writer is None or lock.writer == user): lock.writer = user return file_system_pb2.FileResponse(success=True, message=f\u0026#34;File opened successfully with {lock_type} lock.\u0026#34;) else: return file_system_pb2.FileResponse(success=False,message=\u0026#34;File is read by other user, can not write.\u0026#34;) return file_system_pb2.FileResponse(success=False, message=\u0026#34;File is locked by another user.\u0026#34;) def unlock_file(self, file_path, user): if file_path in self.file_locks: lock = self.file_locks[file_path] if user in lock.readers: lock.readers.remove(user) if lock.writer == user: lock.writer = None return True return False 设置文件锁超时机制：有助于避免死锁情况的发生，确保即使在异常情况下也能够及时释放锁资源。其次，超时机制提高了系统的可用性，防止长时间持有锁资源导致系统阻塞。第三，它促使资源的及时释放，防止长时间占用锁资源，提高系统的资源利用率。此外，文件锁超时机制还有助于降低锁等待时间，提高系统的响应性能，并能够在意外场景下保持系统的稳定性。\n1 2 3 4 5 6 7 8 9 10 11 12 # 启动定期清理过期锁线程 lock_cleaning_thread = threading.Thread(target=name_node.clean_expired_locks, daemon=True) lock_cleaning_thread.start() def clean_expired_locks(self): while True: time.sleep(5) # 每隔5秒清理一次 current_time = time.time() for file_path, lock in list(self.file_locks.items()): if current_time - lock.lock_time \u0026gt; self.lock_timeout: self.unlock_file(file_path, lock.writer) for reader in lock.readers.copy(): self.unlock_file(file_path, reader) 6. 访问权限控制： 本次项目中参考POSIX权限模型，将文件和目录权限分为三个基本类别：所有者、组和其他用户。每个类别都有读（Read）、写（Write）和执行（Execute）三种权限，分别用数字表示为100、010和001。通过三个数字的组合，分别对应所有者、组和其他用户的权限，形成一个三位数的权限表示。通过chmod命令可以动态地调整文件和目录的权限，保障系统安全性和数据隐私。在本次实验中将Client1设置为管理员，即可以对所有文件更改权限；当用户在创建文件时会将自己设置为文件的拥有者，可以对拥有的文件更改权限。这些数据保存在NameNode该文件的对应元数据中。\n客户端通过gRPC连接调NameNode的ChangePermissions接口，传递文件路径、客户端身份标识和新的权限信息。(grpc过程与之前一致，因此不展示详细代码) NameNode 接收到请求后，进行权限校验，确保请求的用户有足够的权限来更改文件的权限。若权限校验通过，NameNode 就会执行更改权限的操作并相应客户端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def ChangePermissions(self, request, context): file_path = request.file_path owner = request.owner new_permissions = request.permissions # 根据 file_path 获取文件元数据并需要修改文件权限 file_metadata = self.file_metadata[file_path] if not file_metadata: return file_system_pb2.FileResponse(success=False, message=\u0026#34;File not found.\u0026#34;) if owner == \u0026#34;1\u0026#34; or owner == file_metadata.owner: file_metadata.permissions = new_permissions return file_system_pb2.FileResponse(success=True, message=\u0026#34;Permissions changed successfully.\u0026#34;) else: return file_system_pb2.FileResponse(success=False, message=\u0026#34;Permissions denied.\u0026#34;) def AddGroup(self, request, context): # 根据 file_path 获取文件元数据 file_metadata = self.file_metadata[file_path] # 在这里根据实际需要修改文件权限 file_metadata.group.append(user) return file_system_pb2.FileResponse(success=True, message=\u0026#34;User added successfully.\u0026#34;) def CheckPermission(self, file_path, user): # 将字符串类型的权限转化为二进制 file_metadata = self.file_metadata[file_path] permission = file_metadata.permissions if user == file_metadata.owner: binary_permission = bin(int(permission[0]))[2:].zfill(3) elif user in file_metadata.group: binary_permission = bin(int(permission[1]))[2:].zfill(3) else: binary_permission = bin(int(permission[2]))[2:].zfill(3) return binary_permission 7. NameNode容错性： 在本次项目中参照HDFS中的结构简化实现了Secondnary NameNode节点，持久化存储主节点中的文件元数据，用于故障修复。在HDFS中，Secondary NameNode的其主要目的是协助主要的NameNode执行检查点操作，以防止NameNode的元数据损坏或丢失，涉及合并编辑日志并创建新镜像等多个操作。本次项目中简化为，定期从NameNode中获取文件元数据并持久化存储，当NameNode发生故障丢生文件元数据时，可以从Secondnary NameNode获取并进行恢复。Secondary Namenode类采用写入文档模拟持久存储，主NameNode中在初始化时使用grpc调用读取备份文件元数据，关键函数如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 def perform_checkpoint(self): # 每隔一段时间执行checkpoint response = self.name_node_stub.GetMetadata(file_system_pb2.FileRequest()) file_metadata_map = {metadata.file_path: metadata for metadata in response.metadata} # 模拟写入持久存储 self.save_metadata_to_file(file_metadata_map) def save_metadata_to_file(self, metadata_map): with open(self.metadata_file_path, \u0026#34;w\u0026#34;) as file: for file_path, metadata in metadata_map.items(): file.write(f\u0026#34;{file_path} {metadata.SerializeToString().hex()}\\n\u0026#34;) def load_metadata_from_file(self): metadata_map = {} with open(self.metadata_file_path, \u0026#34;r\u0026#34;) as file: for line in file: parts = line.split() file_path = parts[0] metadata_hex = parts[1] metadata = file_system_pb2.FileMetadata().FromString(bytes.fromhex(metadata_hex)) metadata_map[file_path] = metadata return metadata_map def PeriodicCheckpoint(self): # 每隔一段时间执行一次检查点 while True: time.sleep(60) self.perform_checkpoint() def GetMetadata(self, request, context): #通过grpc将元数据传递给主Namenode metadata_map = self.load_metadata_from_file() # 返回 SecondaryNameNode 中保存的元数据信息 metadata_list = list(metadata_map.values()) return file_system_pb2.MetadataResponse(metadata=metadata_list) if __name__ == \u0026#39;__main__\u0026#39;: ... # 启动定期执行检查点的线程 checkpoint_thread = threading.Thread(target=secondary_name_node.PeriodicCheckpoint, daemon=True) checkpoint_thread.start() 8. 心跳机制： 通过gRPC通信，DataNode定期向NameNode发送心跳消息，其中包含DataNode的地址。NameNode接收心跳消息后，更新维护的data_nodes字典，记录各个DataNode最近一次的活跃时间戳。同时，NameNode通过定期清理线程，检测data_nodes字典中的时间戳，识别并清理长时间未发送心跳的DataNode，以维持文件系统的稳定性和可靠性。这一心跳机制有助于实时监测DataNode的状态，及时处理可能的故障或失效，从而提高整个分布式文件系统的鲁棒性。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 启动定期清理线程 cleaning_thread = threading.Thread(target=name_node.clean_expired_data_nodes, daemon=True) cleaning_thread.start() def Heartbeat(self, request, context): # 处理DataNode的心跳信息 data_node_address = request.data_node_address self.data_nodes[data_node_address] = time.time() # 更新时间戳 return file_system_pb2.HeartbeatResponse(status=\u0026#34;OK\u0026#34;) # 返回心跳响应 def clean_expired_data_nodes(self): # 定期清理过期的DataNode信息 while True: time.sleep(60) # 每隔60秒清理一次 current_time = time.time() expired_nodes = [addr for addr, timestamp in self.data_nodes.items() if current_time - timestamp \u0026gt; 60] # 假设超过60秒没有心跳就认为过期 for addr in expired_nodes: del self.data_nodes[addr] 1 2 3 4 5 6 7 8 9 10 # 启动心跳发送进程 heartbeat_thread = threading.Thread(target=data_node.send_heartbeat, daemon=True) heartbeat_thread.start() def send_heartbeat(self): while True: time.sleep(10) # 定期发送心跳消息给NameNode print(\u0026#34;Sending heartbeat to NameNode\u0026#34;) with grpc.insecure_channel(self.name_node_address) as channel: stub = file_system_pb2_grpc.FileSystemServiceStub(channel) response = stub.Heartbeat(file_system_pb2.HeartbeatRequest(data_node_address=self.data_node_address)) 四、结果展示 构造运行环境\n下载安装成功依赖环境之后，运行Secondnary NameNode节点；运行NameNode服务器监听localhost:50051；运行五个DataNode服务器(每份文件共有三份副本，分别存在三个DataNode服务器中)，分别监听localhost:50052、localhost:50053、localhost:50054、localhost:50055、localhost:50056。启动三个客户端，Client1(管理员)、Client2、Client3。 展示心跳机制\nDataNode启动之后，与NameNode之间显示心跳信息。 展示文件文件操作\nClient1创建目录、文件，进入目录、回退目录、重命名文件、删除文件、打开文件test，写入数据happy并读取，最后关闭文件。 展示多用户并发访问\nClient2、Client3同时对之前写入的文件test进行读取，可以实现并发读取(读取的是不同副本，一致性的体现)；此时，Client2想要写入test，会失败(因为只支持独占写)；随后Client2与Client3均关闭文件，Clinet2再次打开并写入数据new year,此时Clinet3想要打开文件进行读写会失败，因为Client2获得了写锁。 展示缓存一致性机制\n在上面的步骤中，Client1会对test文件在本地形成缓存，但是随后Client2又修改文件内容；此时，Client1再次读取test文件，缓存能够命中但是发现过时，于是从服务器读取，从而保证一致性，读出数据为happy new year。 展示权限模块\nClient2创建文件，权限为711，即只有文件所有者可以进行读写，Client3无法进行读写。Client1修改权限为777，使得Client3可以读写(还有修改权限组成员的部分在此不展示)。 容错性——NameNode恢复\n运行过程中，重启NameNode程序，可以观察到仍能正确恢复到上一次检查点的状态，文件仍然存在。 测试过程如上所示，运行结果与解释内容较为繁杂在此不做具体展示。\n五、实验中遇到的问题 在实验过程中，遇到了一些挑战和问题，主要包括：\ngRPC是一个高性能、开源和通用的远程过程调用（RPC）框架，熟练高效使用需要一定的学习成本。通过阅读官方文档和示例代码，以及查阅相关资料，逐步掌握了gRPC的基本原理和使用方法。将课程理论内容实践为项目中的一部分也存在着一些挑战，一致性、并发控制、容错性、安全性等等，这些分布式系统的特性在课程中有许多不同实现方式，选择适合本项目的实现方式并顺利实现需要一定的尝试与调整。通过深入理解内容并多次修改代码，最终达到了希望的效果。\n六、实验总结 在该项目的完成过程中，需要考虑多个节点的协同工作，同时处理各种潜在的问题，如网络故障和硬件故障。系统的容错性、一致性和性能等方面都是需要仔细思考和权衡的问题。\n学习和使用gRPC是一个积极的体验。gRPC作为高效的通信框架，简化了节点间的远程过程调用，提高了系统的效率。尽管学习曲线较陡，但一旦掌握，它为分布式系统的通信提供了便利。除此之外，真正将课本中的理论内容实现过后，对于书中的概念原理等等都加深了认识。\n基于作者时间、知识与精力有限，本项目只是一个简化版的分布式文件系统。后续还有大量的工作可以进行完善，比如加入Paxos共识协议等等，本项目全部代码与报告展示已经开源于：\n[项目链接](0702ccc/LiteHDFS: Simplified Distributed File System (based on HDFS) (中山大学分布式系统期末项目) (github.com))\n如有错漏之处 敬请指正🤝\n","date":"2024-03-04T01:02:05+08:00","image":"https://0702ccc.github.io/p/%E6%9E%81%E7%AE%80%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/1_huea26b99c59dafc76270ad4874d154cbc_1376934_120x120_fill_box_smart1_3.png","permalink":"https://0702ccc.github.io/p/%E6%9E%81%E7%AE%80%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/","title":"极简分布式文件系统设计"},{"content":"\r个人网站说明 本博客基于hugo进行创建，目前使用GitHub Page进行托管。博客主要用于记录学习过程中遇到的项目以及一些问题解决办法，目的在于给未来的自己一个更加清晰的回顾方法！基于当前个人时间精力有限😮‍💨，所以还有部分内容没有充分完善，以后有时间一定改💤！\n首页的热力图模块还没适应dark模式； 博客目前将所有博文均发在English界面，中文界面还未设计（中文界面图片显示也有问题\u0026hellip;）； 页面具体布局以及字体设计等还有待完善； 目前博客是以GitHub Page的方式在运行，可能会出现加载比较慢的情况。未来计划将博客打包为容器，并以容器方式部署于服务器或集群当中，更好的与所学知识相结合。 ","date":"2024-03-03T17:47:14+08:00","image":"https://0702ccc.github.io/1.jpg","permalink":"https://0702ccc.github.io/p/text/","title":"text"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt;\r\u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt;\r\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\rCode block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2021-03-11T00:00:00Z","image":"https://0702ccc.github.io/p/markdown-syntax-guide/pawel-czerwinski-8uZPynIu-rQ-unsplash_hud7e36f7e20e71be184458283bdae4646_55974_120x120_fill_q75_box_smart1.jpg","permalink":"https://0702ccc.github.io/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"}]